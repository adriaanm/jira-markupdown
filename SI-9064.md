I think it would be nice to have a simple reduceByKey for some collections like this:
{code:scala}
str.split("").map(l => (l, 1)).reduceByKey(_+_)
{code}
I know there is an easy implementation for reduceByKey as in
[http://stackoverflow.com/questions/15975384/scala-reducebykey-function-use-any-type-that-has-method]
but by adding such a function to collection, we can have a faster implementation for it.
I reimplemented the method, and it's damn fast. On a paired list with 20 entries and 6 different keys, it is 25% faster than Stack Overflow implementation (although, that only works with _+_), and 4.5x faster than bare-hand implementation of it using a bunch of scala maps and reduces:
{code:scala}
pairedList.groupBy(_._1).map(l => (l._1, l._2.map(_._2).reduce(_+_)))
{code}
Take a look at this:
[http://ideone.com/dyrkYM]
