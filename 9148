bq. so I can't exclude that they are easier to infer and they can be moved at the end.

The problem - as I see it - is not the inference of itself the implicit, but the inference of the type parameter of a context bound. As far as I have understood, the context bound places a **restriction** on the type parameter - whereas implicit parameters might help in actually **inferring** a type parameter. Suppose the following:
```scala
class A[X,Y]
class B; class C
implicit val a = new A[B,C]
def f[U,V : Manifest](u : U)(implicit ax : A[U,V]) = ...
```

The intention of the programmer would be:

*get me a `V` for which an implicit `A\[U,V]` exists. Do not let `V` be such that `Manifest\[V]` does not have an implicit associated*

However, the signature of **f** tells the type inference engine that:
*there are two type parameters, `U` and `V`. `U` is the type of `u`. Please fetch some kind of `V` for which an implicit `Manifest` exists. Now, please fetch me an `A\[U,V]`.*

The algorithm here chooses Nothing as the smallest type for which a Manifest exists; but `A\[U,Nothing]` does not exist for any `U` as an implicit. Thus, `f(new B)` will fail with "implicit not found" in spite of `V =:= C` being a perfectly sensible choice.

One would need to write:
```scala
def f[U,V](u : U)(implicit ax : A[U,V], m  : Manifest[V]) = ...
```

to let both implicits be correctly guessed.

I would argue that something called a "bound" should not make the type inference engine make any guess about the type and then keep to it. Imagine if an upper type bound would make type inference assume that if the type parameter is not explicitly specified, then it **must** be itself the upper bound.
