scala.actors.remote.TcpService has an issue related to queueing that causes the service thread to die, effectively cutting off contact with any remote actors associated with that service. The problematic code is in TcpService.send.bufferMessage.

  - If the queue is full (i.e., msgs.length >= TcpService.BufSize) the thread will die with a MatchError because the Some() case is guarded.
  - Related (and trivial) is that the first backlogged message is _always_ queued, even if TcpService.BufSize is zero.

=== What steps will reproduce the problem (please be specific and use wikiformatting)? ===
```scala
import scala.actors.remote._
import RemoteActor._

TcpService.BufSize = 2

val a = select(Node("localhost", 999), 'blah) // Non-existent

for (_ <- 1 to 3)
  a ! 'foo

// Boom!
```


=== What is the expected behavior? ===

Expected behavior is for it not to crash.

=== What do you see instead? ===

```scala
scala.actors.remote.DelegateActor@29a5469e: caught scala.MatchError: Some(List([B@42fcb4f, [B@5dccb1ae)) (of class scala.Some)
scala.MatchError: Some(List([B@42fcb4f, [B@5dccb1ae)) (of class scala.Some)
	at scala.actors.remote.TcpService.bufferMsg$$1(TcpService.scala:88)
	at scala.actors.remote.TcpService.liftedTree1$$1(TcpService.scala:116)
	at scala.actors.remote.TcpService.send(TcpService.scala:100)
	at scala.actors.remote.NetKernel.sendToNode(NetKernel.scala:33)
	at scala.actors.remote.NetKernel.namedSend(NetKernel.scala:39)
	at scala.actors.remote.NetKernel.forward(NetKernel.scala:71)
	at scala.actors.remote.DelegateActor$$$$anonfun$$act$$1$$$$anonfun$$apply$$1.apply(Proxy.scala:180)
	at scala.actors.remote.DelegateActor$$$$anonfun$$act$$1$$$$anonfun$$apply$$1.apply(Proxy.scala:121)
	at scala.actors.ReactorTask.run(ReactorTask.scala:31)
	at scala.actors.ReactorTask.compute(ReactorTask.scala:63)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:147)
	at scala.concurrent.forkjoin.ForkJoinTask.quietlyExec(ForkJoinTask.java:422)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.mainLoop(ForkJoinWorkerThread.java:340)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:325)
```

=== Additional information ===

Here's one way to fix it. I also changed it to discard older messages rather than newer ones, which makes slightly more sense but is still unsatisfying).

```scala
    def bufferMsg(t: Throwable) {
      // buffer message, so that it can be re-sent
      // when remote net kernel comes up
      val msgs = (pendingSends.get(node): @unchecked) match {
        case None => List(data) 
        case Some(msgs) =>  data :: msgs
      }      
      pendingSends += Pair(node, msgs take TcpService.BufSize)  // most recent N
    }
```

I see that the LIFO issue has been fixed. Great!

=== What versions of the following are you using? ===
  - Scala: 2.9
  - Java: 1.6
  - Operating system: OS X
