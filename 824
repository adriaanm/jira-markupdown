David, thank you for your interest in this issue. What you say concerning `reflPoly$$Cache` is true. However, my analysis is that the overall thread-safety of the cache is still maintained despite the update method being not deterministic under concurrent access. I think that the poly-cache implementation of structural methods dispatch only allows the following two abnormal behaviours:

 1. A method is looked-up by one thread, but its entry in the cache is lost when another thread overwrites it. The cache remains valid because the method can be looked-up again next time (and entered into the cache then).
 
 2. Two threads add the same method to the cache. The cache remains valid because the first duplicated method will always subsequently be found. The second duplicated method is wasted cache space, but is not otherwise a problem.
 
Both of these abnormal behaviours create performance penalties: for the first case, a single unnecessary method lookup, and for the second case, an additional equality test and pointer dereference for some subsequent cache lookups. However, such a performance penalty will rarely happen, even on very concurrent code, as it cannot happen anymore once the cache for a call site is built. The other option is to always incur the cost of locking, atomic compare-and-write or volatile fields.

In all fairness, since volatile reads are cheap on modern JVMs, it **may** be beneficial to performance to write a polymorphic cache that does not allow any abnormal behaviour. To be sure requires benchmarking, which is very tricky for such a problem. I'll put this on my todo list, but the priority is low.

In conclusion, I still believe that the 2.8 poly-cache implementation of structural methods dispatch is thread-safe and fast. If you disagree, can you please provide me with a use case that demonstrates the problem, or explain to me very precisely where in the code you see the problem.

Please note also that the 2.7 branch does not contain poly-cache structural method dispatch and may not be thread safe. I had always assumed that poly-cache was part of the 2.7 branch, but apparently, I was mistaken. I suppose that makes for yet another reason to be excited about 2.8: poly-cache is as fast or faster than the 2.7 mono-cache implementation, and can be a lot faster (5x) in some realistic cases.
