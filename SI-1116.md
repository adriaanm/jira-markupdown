Hi,

I'm trying to use trunk, and it looks like functions are no longer
serializable, while they were in Scala 2.7.1. Is there a motivation
for this? Is there a way I can easily say that a closure should be
serializable?

If reasonable, I have attached a very simple patch that I imagine should solve the problem.

Test case below:

object Foo {
 def obj_foo(x : Int) = { () =>  x}
}

import java.io._;

val out = new ObjectOutputStream(new FileOutputStream("foo"));
out.writeObject(Foo.obj_foo(3)) // ok in 2.7.1-final, not ok in
scala-2.7.1.r15559-b20080717010056!

Stack trace:
java.io.NotSerializableException: Foo$$$$anonfun$$obj_foo$$1
       at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1081)
       at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:302)
       at .<init>(<console>:12)
       at .<clinit>(<console>)
       at RequestResult$$.<init>(<console>:3)
       at RequestResult$$.<clinit>(<console>)
       at RequestResult$$result(<console>)
       at sun.reflect.Nat...

Thanks,
David Hall
Forgot the formatting:

{code}
object Foo {
 def obj_foo(x : Int) = { () =>  x}
}

import java.io._;

val out = new ObjectOutputStream(new FileOutputStream("foo"));
out.writeObject(Foo.obj_foo(3)) // ok in 2.7.1-final, not ok in
scala-2.7.1.r15559-b20080717010056!

Stack trace:
java.io.NotSerializableException: Foo$$$$anonfun$$obj_foo$$1
       at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1081)
       at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:302)
       at .<init>(<console>:12)
       at .<clinit>(<console>)
       at RequestResult$$.<init>(<console>:3)
       at RequestResult$$.<clinit>(<console>)
       at RequestResult$$result(<console>)
       at sun.reflect.Nat...
{code}
Sorry to reopen so late:

I'd actually prefer my solution, for a couple of reasons.

 * Java will throw the exception for the object that isn't serializable when I try to serialize, rather than for the generated function object, as in this solution. This saves me from using javap every time a function doesn't serialize.

 * I can't serialize HOF's in this framework, since the compiler will always assume that the function in question can't be serialized. I can work around this in library code somewhat, but it's less than optimal.

New test case:
{code}
object Foo {
  def foo(x : Int) = {() =>x} 
  def bar(f : Int=>Int) = {() =>f(3)}
}

import java.io._;

val out = new ObjectOutputStream(new FileOutputStream("foo"));
out.writeObject(Foo.foo(3)); // Works great, thanks!
out.writeObject(Foo.bar(3+)); // Still doesn't work.
{code}

Thanks!

-- David

One more example that doesn't work:

{code}
out.writeObject(Set()) // fine
def foo(x : Set[Any]) = {() => x}
out.writeObject(foo(Set()))  // not fine
{code}

-- David

Thinking about this, attaching @serializable to trait FunctionN doesn't make sense. Maybe a better solution is making autogenerated closures always serializable?

-- David
Let me push back once; I won't make a big todo over this, though I'd really like this to work.

My use case is fairly simple: I want to make an almost perfectly transparent way of distributing tasks over the network for scientific computing. MapReduce, if you will.
{code}
val nums = distributor.distribute(Range(0 to 1000));
nums.map{x * 200}.reduce{_+_}; // reduce because we need full associativity from the operator.
{code}

The only thing blocking this library is this change, or a reasonable work around. I'd really like to avoid having to say "new SerializableFunction{ def apply(x : Param) = /*...*/ } when Scala just needs this one thing. 

As for safety, a class marked serializable can only be serialized if all of its members can be serialized (and so on down the heirarchy) thanks to the JVM's runtime checks. Automatically attaching @serializable to closures would in no way effect the safety of operations, and only closures that included fully serializable members would be serializable anyway, which is what the static check is attempting to do. That is, anything your check would catch is caught by the JVM anyway, and as it stands, it's blocking otherwise perfectly serializable functions from being serialized.

Regarding the safety:
{code}
class A;
@serializable class B(val a:A);

object C {
  def main(args:Array[String]) {
    import java.io._;

    val out = new ObjectOutputStream(new FileOutputStream("foo"));
    out.writeObject(new B(new A));
    out.close();
  }
}
{code}

Compiling and running this code yields:

{code}
java.io.NotSerializableException: A
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1156)
{code}

I can't think of a single instance where undesired behavior would occur if the check in place were removed and replaced with a pass. Moreover, the current check  stops code that statically cannot be shown to be serializable, but is in fact serializable, from being serialized, but the error signaling this failure still occurs at runtime. In other words, the static check doesn't seem to actually statically guarantee me anything useful.

Perhaps I'm wrong, but it seems like this couldn't reasonably pose any problems in the JVM. If I'm wrong, is the only workaround for me to force users to use the Java-like syntax of new SerializableFunction[A,B] { def apply(x : A):B = { } }? Dare I ask for a compiler flag?[[BR]]

Regardless of the eventual outcome, the current fix doesn't currently do what it purports to do:
{code}
object X {
  def foo() ={ val c = 3; () => c}
  def bar() = {val c = new scala.collection.immutable.HashSet[Int]; () => c};

  def main(x : Array[String]) {
    import java.io._;
    classOf[scala.collection.immutable.HashSet[Int]].getInterfaces.foreach{println}
    val out = new ObjectOutputStream(new FileOutputStream("foo"));
    out.writeObject(new scala.collection.immutable.HashSet[Int]);
    out.writeObject(foo());
    out.writeObject(bar());
  }
}
{code}

gives this output:

{code}
$$ scala X
interface scala.collection.immutable.Set
interface scala.collection.mutable.FlatHashTable
interface scala.ScalaObject
interface java.io.Serializable
java.io.NotSerializableException: smr.X$$$$anonfun$$bar$$1
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1156)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:326)
	at smr.X$$.main(test.scala:15)
	at smr.X.main(test.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at scala.tools.nsc.ObjectRunner$$$$anonfun$$run$$1.apply(ObjectRunner.scala:75)
	at scala.tools.nsc.ObjectRunner$$.withContextClassLoader(ObjectRunner.scala:49)
	at scala.tools.nsc.ObjectRunner$$.run(ObjectRunner.scala:74)
	at scala.tools.nsc.MainGenericRunner$$.main(MainGenericRunner.scala:164)
	at scala.tools.nsc.MainGenericRunner.main(MainGenericRunner.scala)
{code}

However, HashSet is marked as serializable...

Thanks,
David
First, if we can get this little part fixed so that the check does what it's supposed to do, I have a workaround for the larger problem.

Now, I figured out what's wrong with the current fix; I just don't know how to fix it.

The static check added can't tell if classes defined in other translation units are serializable or not. Or rather, the symtable doesn't keep track of classes' annotations that it's not currently generating. What's needed is for the check to actually look for the classes and check their annotations. I don't know nearly enough to do this myself.

Thanks!

-- David
