This won't compile:
{code}
object A {
  class G extends H
  class H
  class U extends G

  def foo(h: G) = 55
  def foo[T](h: T) = 66

  def main(args: Array[String]) {
    val x = foo(new U)
    println("x = " + x)
    Array("", "")
  }
}
{code}
but it's ok:
{code}
object A {
  class G extends H
  class H
  class U extends G

  def foo(h: G) = 55
  def foo[T](h: T) = 66

  def main(args: Array[String]) {
    val x = foo(new U)
    println("x = " + x)
    val a = Array("", "")
  }
}
{code}
In both cases expected type is undefined. So I can't see defference.
see reason in SI-2667
But You don't feel that it's strange?
Whatever what return type if it's Unit? I what to has some last statement like function call, why I should add something additional to have right compilation. 
It's like in Java you want:
{code}
int foo() {
  return 23;
}
void x() {
  foo();
}
{code}
Why it shouldn't compile with overloading resolution?
Duplicate with SI-2667
This issue can be narrowed down as:

{code}
object A {
  
  def test {
    Array("", "")
  }

}
{code}
scalac complains: 
{code}
 error: overloaded method value apply with alternatives (x: Unit,xs: Unit*)Array[Unit] <and> (x: Double,xs: Double*)Array[Double] <and> (x: Float,xs: Float*)Array[Float] <and> (x: Long,xs: Long*)Array[Long] <and> (x: Int,xs: Int*)Array[Int] <and> (x: Char,xs: Char*)Array[Char] <and> (x: Short,xs: Short*)Array[Short] <and> (x: Byte,xs: Byte*)Array[Byte] <and> (x: Boolean,xs: Boolean*)Array[Boolean] cannot be applied to (java.lang.String,java.lang.String)
    Array("", "")
{code}

But the following is ok:
{code}
object A {
  
  def test = {
    Array("", "")
  }

}
{code}

More:

{code}
scala> def test {Array(1)}   // ok
test: Unit

scala> def test {Array("")}
<console>:4: error: overloaded method value apply with alternatives (x: Unit,xs: Unit*)Array[Unit] <and> (x: Double,xs: Double*)Array[Double] <and> (x: Float,xs: Float*)Array[Float] <and> (x: Long,xs: Long*)Array[Long] <and> (x: Int,xs: Int*)Array[Int] <and> (x: Char,xs: Char*)Array[Char] <and> (x: Short,xs: Short*)Array[Short] <and> (x: Byte,xs: Byte*)Array[Byte] <and> (x: Boolean,xs: Boolean*)Array[Boolean] cannot be applied to (java.lang.String)
       def test {Array("")}

scala> def test {List(1).toArray}
<console>:4: error: polymorphic expression cannot be instantiated to expected type;
 found   : [B >: Int]Array[B]
 required: Unit
       def test {List(1).toArray}
                         ^
scala> def test {List("").toArray}
<console>:4: error: polymorphic expression cannot be instantiated to expected type;
 found   : [B >: java.lang.String]Array[B]
 required: Unit
       def test {List("").toArray}
                          ^

{code}
it seems the problem here is in `doTypedApply`, where we first filter out alternatives with the wrong number of parameters using:

{code}
var sym = fun.symbol filter { alt =>
  isApplicableSafe(context.undetparams, followApply(pre.memberType(alt)), argtypes, pt)
{code}

which causes the alternative 
{code}
[T](xs: T*)(implicit evidence$$2: scala.reflect.ClassManifest[T])Array[T]
{code}

to be filtered out because `Array[Nothing]` is not a subtype of `Unit` (`pt`).

Since it's only an optimisation anyway, I propose to be less strict and replace `pt` by `WildcardType`.

Martin: please advise & re-assign to me 

(In r19806) close SI-2665 and close SI-2667: use weak conformance in polymorphic case of isApplicable
reviewed by: odersky

exprTypeArgs now takes a comparison function: isWeaklyCompatible is passed in isApplicable's typesCompatible (to mimic what happens in the monomorphic case)
Martin: please review as this is different from my original proposal (that one broke type inference, this one passes all tests and does not slow down quick.comp)
