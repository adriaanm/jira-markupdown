Negative number literals are handled inconsistently for floating point numbers and integral numbers:

```scala
Welcome to Scala version 2.8.0.RC6 (Java HotSpot(TM) 64-Bit Server VM,
Java 1.6.0_20).
Type in expressions to have them evaluated.
Type :help for more information.

scala> -33.5f max 33
res0: Float = 33.0

scala> -33.5f.max(33)
res1: Float = -33.5

scala> -34 max 33
res2: Int = 33

scala> -34.max(33)
<console>:1: error: ';' expected but '.' found.
      -34.max(33)
         ^
```

Part of the problem is the fix for #2378 in r19950 which replaces an floating point integer ~~5.63 by 5.63.unary_~~.

Here's my analysis which I posted on the mailing list as well:

I've done some diggin' (and moved to internals):

Originally(*), and despite of the language specification (**),
negative number literals could not appear in a select expression
(-1.max(5)). Since r19950 which 'fixed' #2378 (***), the balance
between integer and floating point literals drifted: for with what the
parser was concerned, negative floating point literals received no
special treating any more, so -5f.max(2) was seen as
(5f.max(2)).unary_-, simple negative floating literals as 5f.unary_-
(*!*). For negative integer literals the situation stayed the way it
was the way before: -1.max(5) was simply not allowed by the parser.

IMO the least surprising behaviour would be if

-5f.max(2)
-5f max 2
-5.max(2)
-5 max 2

would all consistently return 2. Negative number literals are negative
number literals are negative number literals.

To make that work one could use a patch like that:

```scala
--- a/src/compiler/scala/tools/nsc/ast/parser/Parsers.scala
+++ b/src/compiler/scala/tools/nsc/ast/parser/Parsers.scala
@@ -1243,7 +1243,7 @@ self =>
          val name = unaryOp()
          in.token match {
            // Don't include double and float here else we lose -0.0
-            case INTLIT | LONGLIT => literal(true)
+            case INTLIT | LONGLIT | FLOATLIT | DOUBLELIT => simpleExprRest(atPos(in.offset)(literal(true)),true)
            case _ => Select(stripParens(simpleExpr()), name)
          }
        }
```

and then fix #2378 properly by fixing fjbg. It has a small regression
risk because of the new behaviour introduced by the fix for #2378
(which the OP was about). That's a pity because the new and
inconsistent behaviour will probably ship with 2.8.0.


 * (*) That's r3930, the commit with the unimpressive empty log message where nsc sprang to life.
 * (**) The SLS would allow both 5.unary_- and the literal -5 and does at least not specify how to resolve this ambiguity.
 * (***) The real cause of SI-2378 can be found in the backyard of the backend: FJBG generates a DCONST_0 if a double literal == 0.0, what -0.0 is.
 * (*!*) This behaviour caused SI-3486, where negative constants in annotations wouldn't be possible any more.
What gives me pause about "Negative number literals are negative number literals are negative number literals" is that it requires us to have non-uniform precedence rules, unless you want unary_- to bind more tightly than "." in all cases, which would be a pretty big change and also difficult to reconcile with the other unary methods having a lower precedence.  Example.
```scala
case class Foo(val x: Double) {
  def unary_- : Foo = Foo(-x)
  def +(other: Foo): Foo = Foo(x + other.x)
}

scala> -5.0.+(10.0)
res17: Double = -15.0

scala> -Foo(5.0).+(Foo(10.0))  
res18: Foo = Foo(-15.0)
```
That is the current behavior: same outcome.  If the first one yields 5.0 instead, then we have introduced the kind of irregularity martin is usually against (although I understand this is an unusual situation.)

It's hard to imagine a really pleasing outcome emerging because of the ambiguity at both ends.  If you see the sequence -x. then the "-" might be a unary method or, it is proposed, a piece of a negative literal; the . might be a method call or a decimal point, and the type of x varies based no that; the next token's interpretation depends no what the type of x is, since there may be an implicit conversion; and the interpretation of the - depends on the preceding.

I'm not opposing anything, only trying to avoid implementing something which will introduce equally undesirable issues.

Although it is not a solution, there is a simple, almost zero cost measure we can take to simplify the matter a lot: disallow the pointless literal double forms like "5." and "5.d".  They buy us nothing.
(In r23024) Restoring negative literal parsing behavior to what should be
the least surprising option.  Thanks much to Johannes Rudolph for
identifying the bug in the bytecode generator which needed addressing
for us to arrive at proper -0.0 behavior, and for writing the majority
of this patch.

A '-' followed immediately by either a number or a period should
now always be treated as a single numeric literal, which means the
minus binds more tightly than anything else.  A specific example
of how this differs from 2.8 final is:

  -5.+(10) == 5.0   // and not -15.0

The full range of potentially ambiguous parses involving prefix
operators, numbers, and dots is quite large and still needs to be
completely and clearly specified.

Closes #2378 and #3657, review by odersky, jrudolph.
