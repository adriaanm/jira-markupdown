{{{
BigDecimal("-4.6010652208491219E+1556245283").hashCode
}}}

Explodes with an OutOfMemoryError even with a 4GB heap.  (tested using PaulP's sbt-extras script with SBT_MEM=4096)  The issue is that the BigDecimal#isWhole function is extremely heap-intensive for large numbers.  This is actually a bit silly, given that numbers like the one I pasted are never, ever going to be convertible to either Int *or* Double, which is what the isWhole check is intended to accomplish.

My proposal would be to change the implementation of BigDecimal#hashCode to do a quick sanity check on the size of the value to see if it's even *possible* to fall into the range of Int/Double.  If not, then check the sign and return the value that Double's ## would have returned anyway (Double.POSITIVE_INFINITY or Double.NEGATIVE_INFINITY).  As things stand, this is literally a security whole in Scala for people who parse user-specified text as BigDecimal, even with non-ARBITRARY contexts.
I don't know why isWhole is so expensive, but it has to know if it may be equal to a BigInt, and the size is irrelevant.  If BigDecimal(1) == (1: Int) && (1: Int) == BigInt(1), then BigDecimal(1) == BigInt(1) and BigDecimal(1).hashCode == BigInt(1).hashCode.

So unless you like the idea that somewhere BigInt(X) == BigDecimal(X) but BigInt(X + 1) != BigDecimal(X + 1), the hashCodes of BigDecimals must be coordinated with those of BigInts.  Regardless of size.  To do this, the BigDecimal must check whether it can conceivably be equal to a BigInt, or the hashcode scheme has to be such that BigDecimals/BigInts provide the same one when they are equal.  If there is a better test than "isWhole", which does not have the ring of a heap-exhausting method, then please suggest it.

It looks like BigDecimal(a).hashCode is *not* constant for whole values of a > Long.MaxValue, which is contrary to what I had thought.  It turns out that BigDecimal(a).hashCode == 0 where !BigDecimal(a).isWhole && (a > Double.MaxValue || a < Double.MinValue).  But, determining that we need to get into that case still requires the isWhole check.

I would argue that BigInt and BigDecimal are being too aggressive with their large-value hashCodes.  Honestly, if someone has a number that large, they've pretty much given up on efficiency.  Let them deal with the hash collisions.  This is especially valid (imo) in light of the fact that hashes will *always* collide for non-whole values greater than Double.MaxValue.  Given that this avoids the call to isWhole altogether for sufficiently large-magnitude BigDecimal/BigInt values, it bypasses the performance issues with isWhole.
I don't mean to defend any of the present code, it's just that either one accepts the native equals and hashcode methods of BigInt and BigDecimal -- and one should probably consider doing exactly this, and using extension methods for any other functionality -- or one messes with them, and all kinds of consequences arise.

To be clear, and despite the fact that (see below) the goal is not achieved, the hashcodes for these classes are not modified from the native ones for anything to do with efficiency.  There is only one reason: "equal objects must have equal hashcodes." So collision rates are beside the point.

I checked, and we're not even doing the thing I talked about, so the thing I thought was a bad idea is already the way that it is, by which I mean:
{code}
scala> BigDecimal(Long.MaxValue) == BigInt(Long.MaxValue)
res9: Boolean = true

scala> (BigDecimal(Long.MaxValue) pow 2) == (BigInt(Long.MaxValue) pow 2)
res10: Boolean = false
{code}
So it's not like there's any wonderful behavior to preserve here.  I'm not going to touch any of this, I'm only trying to illuminate it a little for whoever may attempt something.

Well this is nice, somehow even with the String constructor BigDecimal loses precision through scaling.
{noformat}
scala> BigDecimal(new java.math.BigDecimal("85070591730234615847396907784232501249"))
res22: scala.math.BigDecimal = 85070591730234615847396907784232501249

scala> BigDecimal("85070591730234615847396907784232501249")
res23: scala.math.BigDecimal = 8.507059173023461584739690778423250E+37
{noformat}
That's why they come out unequal in my previous comment - the BigDecimal version gets rounded.

So these hashCodes have to be equal.  Of course, it doesn't WORK or anything - that would be too much to ask - but this is why it can't keep its paws off of hashCode.
{noformat}
scala> BigDecimal(new java.math.BigDecimal("85070591730234615847396907784232501249")) == BigInt("85070591730234615847396907784232501249")
res24: Boolean = true

scala> BigDecimal(new java.math.BigDecimal("85070591730234615847396907784232501249")).## == BigInt("85070591730234615847396907784232501249").##
res25: Boolean = false
{noformat}
