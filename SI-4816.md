When an array of Bytes containing a Long is written to a file using java.io, and read back using scala.io.Source, a different value is obtained.

Reproducing the issue using the console:

scala> import java.io.FileOutputStream
import java.io.FileOutputStream

scala> import java.nio.ByteBuffer
import java.nio.ByteBuffer

scala> val f = new FileOutputStream("test1")
f: java.io.FileOutputStream = java.io.FileOutputStream@10def14f

scala> val msg = new Array[Byte](8)
msg: Array[Byte] = Array(0, 0, 0, 0, 0, 0, 0, 0)

scala> val bbuf = ByteBuffer.wrap(msg)
bbuf: java.nio.ByteBuffer = java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]

scala> bbuf.putLong(233)
res4: java.nio.ByteBuffer = java.nio.HeapByteBuffer[pos=8 lim=8 cap=8]

scala> f.write(msg)

scala> f.close

scala> import scala.io.Source
import scala.io.Source

scala> val f = Source.fromFile("test1")
f: scala.io.Source = non-empty iterator

scala> f.toArray.map(_.toByte)
res0: Array[Byte] = Array(0, 0, 0, 0, 0, 0, 0, -56)

scala> res0
res1: Array[Byte] = Array(0, 0, 0, 0, 0, 0, 0, -56)

scala> import java.nio.ByteBuffer
import java.nio.ByteBuffer

scala> val bbuf = ByteBuffer.wrap(res0)
bbuf: java.nio.ByteBuffer = java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]

scala> bbuf.getLong()
res2: Long = 200
Hmm, interesting. Shouldn't the byte->char conversion be a bijection though? This works:

scala> val a = Array[Byte](0,0,0,0,0,0,0,-23)
a: Array[Byte] = Array(0, 0, 0, 0, 0, 0, 0, -23)

scala> a.map(_.toChar).map(_.toByte)
res7: Array[Byte] = Array(0, 0, 0, 0, 0, 0, 0, -23)
Well, a Char is a 16-bit unsigned number and a Byte is an 8-bit signed number, so it won't be a bijection in general.   But in this case it was not the map operations that caused the numerical change, but rather it was the fact that you wrote the file using a java.io.OutputStream, which deals with raw bytes, but read the file using scala.io.Source (or java.io.FileReader), which deals with character data.   

By convention, Chars in Java and Scala are treated as Unicode [UTF-16](http://en.wikipedia.org/wiki/UTF-16/UCS-2) code units (see [java.lang.Character](http://download.oracle.com/javase/6/docs/api/java/lang/Character.html) for more info on the java side).  So under the hood, scala.io.Source interprets the file using some default encoding and *translates* it to UTF-16.  On OS X, the JVM apparently defaults to [MacRoman](http://en.wikipedia.org/wiki/Mac_OS_Roman) and if you dig through the character tables, you'll find that 233 in MacRoman is the same character as 200 in Unicode.

Here are a few tips for avoiding some of these character-encoding issues:

1.  When working with raw binary data, use Bytes and Byte-based APIs.
2.  When working with text, use Chars and Char-based APIs.
3.  When doing Character-based IO, keep in mind that some (possibly implicit) character encoding will be used to convert between the text and the raw bytes being written or read.  This conversion *need not* preserve numerical values of the Chars or of the raw bytes.
4.  It's usually better to explicitly specify an encoding rather than relying on the platform's default.   See [this article](http://illegalargumentexception.blogspot.com/2009/05/java-rough-guide-to-character-encoding.html#javaencoding_encodings) for some reasons why.



