Two issues here:

This scala code:
{code}
val x = Array[Int](1,2,3)
{code}

becomes 
{code}
private[this] val x: Array[Int] = scala.Array.apply[Int](1, 2, 3)(reflect.this.Manifest.Int);
{code}
after typer which later compiles into
{code}
Testclass.this.x = scala.Array.apply(scala.this.Predef.wrapIntArray(Array[Int]{1, 2, 3}), reflect.this.Manifest.Int()).$$asInstanceOf[Array[Int]]();
{code}

Needless to say, this is much more complicated than necessary; enough would be
{code}
Array[Int]{1, 2, 3}
{code}
which is a tree of type `ArrayValue`.

The second issue appears if the declaration is changed to simply
{code}
val x = Array(1,2,3)
{code}
in this case another (apparently manually specialized) overload of Array.apply is used:
{code}
Testclass.this.x = scala.Array.apply(1, scala.this.Predef.wrapIntArray(Array[Int]{2, 3}));
{code}

The second issue could be solved by using specialization in Array.apply and getting rid of all the overloads (they might have a use, which escapes me, relating to boxing, weak conformance etc). Then again, I think the first issue would be solved by making array creation an intrinsic by transforming Array.apply to ArrayValue trees in the first place, which would make Array.apply obsolete.
