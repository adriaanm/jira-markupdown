What gives me pause about "Negative number literals are negative number literals are negative number literals" is that it requires us to have non-uniform precedence rules, unless you want unary_- to bind more tightly than "." in all cases, which would be a pretty big change and also difficult to reconcile with the other unary methods having a lower precedence.  Example.
{code}
case class Foo(val x: Double) {
  def unary_- : Foo = Foo(-x)
  def +(other: Foo): Foo = Foo(x + other.x)
}

scala> -5.0.+(10.0)
res17: Double = -15.0

scala> -Foo(5.0).+(Foo(10.0))  
res18: Foo = Foo(-15.0)
{code}
That is the current behavior: same outcome.  If the first one yields 5.0 instead, then we have introduced the kind of irregularity martin is usually against (although I understand this is an unusual situation.)

It's hard to imagine a really pleasing outcome emerging because of the ambiguity at both ends.  If you see the sequence -x. then the "-" might be a unary method or, it is proposed, a piece of a negative literal; the . might be a method call or a decimal point, and the type of x varies based no that; the next token's interpretation depends no what the type of x is, since there may be an implicit conversion; and the interpretation of the - depends on the preceding.

I'm not opposing anything, only trying to avoid implementing something which will introduce equally undesirable issues.

Although it is not a solution, there is a simple, almost zero cost measure we can take to simplify the matter a lot: disallow the pointless literal double forms like "5." and "5.d".  They buy us nothing.
