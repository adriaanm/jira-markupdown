Usually, a class can be extended with traits and then an instance
created. What I want is the ability to extend a variable,
an instance of a class, with traits.

Consider
```scala
trait Foo { self: String =>
  def fancy: String = "*" + self + "*"
}
val s = "hi" with Foo
s.fancy
// which yields "*hi*"
```
Here an instance is extended with a trait.
This would be useful in allowing end users the ability
to extend objects generated by third-party factories
and libraries given the API but not necessarily the
implementation.

As an example,
  Third-party API factory/library:
```scala
object Persister {
  def apply(): Persister = .... private implementation
}
trait Persister {
  def store(key: String, data: Any): Unit
  def retrieve(key: String): Any
  protected def isKeyValid(key: String): Boolean
}
```

  User code which adds logging, auditing and a permission check:
```scala
trait Audit extends Persister {
  def store(key: String, data: Any): Unit = {
    Aditor.audit("store", key, data)
    super.store(key, data)
  }
  def retrieve(key: String): Any = {
    val data = super.retrieve(key)
    Aditor.audit("retrieve", key, data)
    data
  }
}
trait Logger extends Persister {
  def store(key: String, data: Any): Unit = {
     Log.trace("Storing key="+key)
     super.store(key, data)
  }
  def retrieve(key: String): Any = {
    Log.trace("Retrieving key="+key)
     super.retrieve(key)
  }
  protected def isKeyValid(key: String): Boolean = {
    val b = super.isKeyValid(key)
    if (!b) Log.trace("Invalid key="+key)
    b
  }
}
trait Permission extends Persister {
  def store(key: String, data: Any): Unit = {
    Permit.(classOf[Persister], "store")
    super.store(key, data)
  }
  def retrieve(key: String): Any = {
    Permit.(classOf[Persister], "retrieve")
    super.retrieve(key)
  }
}

// User extends persister
val persister = Persister() with Logger with Audit with Permission
```
Some of this might be achieved with a (implicit) wrapper, but the
problem with such an approach is that it adds an additional object and
an instance variable reference to the underlying implementation - both
of which increase the memory usage - and, for my needs, an approach
that uses a proxy or wrapper simply uses too much memory when one has
tens of thousands of client trees each with many potentially extensible
objects.

One could also imagine being able to simply extend an object with
an "anonymous" trait:
```scala
val s = "hi" { self: String =>
  def fancy: String = "*" + self + "*"
}
s.fancy
// which yields "*hi*"
```
This could be referred to an **explicit** pimping (rather than implicit). 
Consider:
```scala
def pimp(i: Int): Int = i { self =>
  def power(n: Int): Int = java.lang.Math.pow(self, n).toInt
}
```
Using this one could do the following:
```scala
> val i = pimp(4)
> i.power(3)
64
```
Ok, this is not a valid use-case since the pimp function return type is
an Int and not a pimped-Int (even thought is does return a pimped-Int).
So, one can not call "power(3)" on "i". I guess, the better approach is to
define a trait with the "power" method and then have the "pimp" return
an "Int with Trait":
```scala
trait IPower { self: Int =>
  def power(n: Int): Int = java.lang.Math.pow(self, n).toInt
}

def pimp(i: Int): Int with IPower = i with IPower
```
Then the REPL session might still be:
```scala
> val i = pimp(4)
> i.power(3)
64
```

Where do Explicits stand?

Consider that there is a third-party library with a trait Foo and
a factory object, 3rdPartyLib, with the method "def getFoo: Foo".
The Foo trait has a public and a protected method.
The coder using the library want to wrap Foo's methods with
her own code.

```scala
// In third-party library

  trait Foo {
    def opOne: Unit
    protected def opTwo: Boolean
  }

// How Foo is to be pimped

    PimpedFoo extends Foo { self: Foo =>
      // CLOS-like around method
      def opOne: Unit = {
        logger.trace("Before calling opOne")
        super.opOne
        logger.trace("After calling opOne")
      }
      // CLOS-like before method
      protected def opTwo: Boolean =
        if (someCondition) false
        else super.opTwo
    }

// User code using the third-party library

  {
    // block of code ...
    // Pimp f1
    val f1 = 3rdPartyLib.getFoo
    // Do not Pimp f2
    val f2 = 3rdPartyLib.getFoo
    // use f1 and f2
  }
```

Here, within the same block of code, one call to get Foo returns
a Foo that is pimped while the next does not.

With the proposed Explicits, one would do the following:

```scala
  {
    // block of code ...
    // Pimp f1
    val f1 = 3rdPartyLib.getFoo with PimpedFoo
    // Do not Pimp f2
    val f2 = 3rdPartyLib.getFoo
    // use f1 and f2
  }
```

which at the end coders level is very simple syntax with no new
Scala keywords.

The existing "pimping" capability using implicits certainly
added complexity to the language, additional key words had
to be added, much harder to figure out what is happening,
can not pimp existing methods or protected methods, can not
add an instance field to the object being pimped and is far
less intuitive to most programmers. Basically, when it
comes to pimping an object, the implicits approach
is rather poor; at best a complex, incomplete solution.

Explicits does require that a new class is created that the
explicitly pimped object is now a member of and, as a result,
the pimping create a new object and is permanent (for the
rest of the object's life cycle, it has the new methods and
variables).


What are the prospects of Explicits being added to Scala?
Explicits are useful to pimp 3rd-party libraries. As such,
enterprise application developers would certainly find it
useful and its intuitive simplicity would be appreciated
by all Java programmers trying to transition to Scala.

On the other hand, language designers are members of neither
of the proceeding categories and, it would seem, are
content with the complexity and limitations of Implicits.
So, Explicits are dead unless someone, at their cost,
wishes to extend Scala. But, then, without the keeper of
Scala support, such an extension will not be added to
the main branch - hence dead.
Below is an augmentation the capabilities offered by Explicits
but does require a new key word.
That said, it does close a rather gapping hole in Scala
that many folk have run into.

The additional feature is the "expandTo" construct which
is part of any object's API and takes a class as a parameter:

```scala
    val objExpanded = objBase.expandTo[SomeClass]
```

At runtime (or, when possible, at compile-time) the expression
Explicitly pimps the objBase into an object which is now
an instance of the "SomeClass". This succeeds if "SomeClass"
is a derived class of objBase.getClass with only the
addition of one or more traits. Failure results in an
exception much like a run-time cast can fail with an exception.

Consider, you have an object created using an anonymous class
which includes one or more additional traits (see below).
The created object is an instance of the traits.
One then takes a clone of the object. The cloned object
is NOT an instance of the traits

```scala
  import scala.collection.mutable.ArrayBuffer
  import scala.collection.mutable.SynchronizedBuffer

  object Main {
    def main(args: Array[String]): Unit = {
      val objBase = new ArrayBuffer[Int] with SynchronizedBuffer[Int] { }

      if (objBase.isInstanceOf[SynchronizedBuffer[_]])
        println("obj is SynchronizedBuffer")
      else
        println("obj is NOT SynchronizedBuffer")

      val objClone = objBase.clone

      if (objClone.isInstanceOf[SynchronizedBuffer[_]])
        println("clone is SynchronizedBuffer")
      else
        println("clone is NOT SynchronizedBuffer")
    }
  }
```

This prints:
```scala
obj is SynchronizedBuffer
clone is NOT SynchronizedBuffer
```

Using the "expandTo" construct, if the line above which clones
the objBase was written as:

```scala
      val objClone = objBase.clone.expandTo[objBase.getClass]
```

Then the objClone would be a TRUE clone, it would an instance of
SynchronizedBuffer.

It could also be used when serializing/de-serializing objects.
Consider the following code:
```scala
  import scala.collection.mutable.ArrayBuffer
  import scala.collection.mutable.SynchronizedBuffer

  object Main {
    def serialize(obj: Any): Array[Byte] = {
      // serialize the object and return byte array
    }
    def deserialize(bytes: Array[Byte]): Any = {
      // de-serialize the byte array and return object
    }
    def deserialize(bytes: Array[Byte], expandToClass: Class[_]): Any = {
      deserialize(bytes).expandTo[expandToClass]
    }

    def main(args: Array[String]): Unit = {
      val objBase = new ArrayBuffer[Int] with SynchronizedBuffer[Int] { }

      val objCopy = deserialize(serializing(objBase))

      if (objCopy.isInstanceOf[SynchronizedBuffer[_]])
        println("copy is SynchronizedBuffer")
      else
        println("copy is NOT SynchronizedBuffer")
    }
  }
```

This prints:
```scala
copy is NOT SynchronizedBuffer
```


But if the serializing/de-serializing line above was replaced with
```scala
      val objCopy = deserialize(serializing(objBase), objBase.getClass)
```

Then the objCopy would be an instance of the trait, SynchronizedBuffer.

So many real uses for Explicits.


There is a particular issue with Scala collections which
can be resolved using the above "expandTo[clz]" operation
and a companion operation, "optionalExpandTo[clz]".
Specifically, many of Scala collection's base methods
found in TraversableLike.scala use the "newBuilder"
method or the "CanBuildFrom" implicit. Currently, such
usage is broken.

Again, consider the synchronized ArrayBuffer:
```scala
val buf = new ArrayBuffer[Int] with SynchronizedBuffer[Int] { }
```
When one uses (as an example) the "filter" method on "buf", one
gets back not a synchronized ArrayBuffer, but rather simply
an ArrayBuffer. Such behavior violates the software engineering
principle of "Minimizing the number of WTFs"; it is rather
unexpected and there is no simple work-around (have every user test 
every use of filter and when it does not return the expected type,
have extra code that created the correct type and copies
the filter method result into it ... have everyone do this
everywhere filter is used ... and for all the other TraversableLike
methods that use "newBuilder" .... I think not).

Concerning the "CanBuildFrom" implicit, this is used in
TraversableLike methods that most of the time return a
type that is different from the original type, but not
allways. Consider:
```scala
val buf = new ArrayBuffer[Int] with SynchronizedBuffer[Int] { }
val newbuf = buf map {v => v}
```
What would one expect this to return?
Clearly, if a synchronized ArrayBuffer went in, a synchronized
ArrayBuffer should come out, but it does not. An ArrayBuffer
is returned; again violating the above software engineering principle.

So, how does explicit pimping help?

In the case of TraversableLike methods that use "newBuilder",
they should be altered to all use the "expandTo[clz]" operator
on the collection object being returned. For example:
```scala
  def filter(p: A => Boolean): Repr = {
    val b = newBuilder
    for (x <- this)
    if (p(x)) b += x
    b.result.expandTo[getClass]
  }
```
This will now return a synchronized ArrayBuffer as
expected.

For TraversableLike methods that use the "CanBuildFrom"
implicit, they should be re-written so that the
"optionalExpandTo[clz]" operator is applied to the
collection type being return   The return type
is expanded to the given class type if the class type
is a derived type of the current class and, otherwise,
the return value is returned unchanged.
For example:
```scala
  def map[B, That](f: A => B)(implicit bf: CanBuildFrom[Repr, B, That]): That = {
    val b = bf(repr)
    b.sizeHint(this)
    for (x <- this) b += f(x)
    b.result.optionalExpandTo[getClass]
  }
```
In the case of:
```scala
val buf = new ArrayBuffer[Int] with SynchronizedBuffer[Int] { }
val newbuf = buf map {v => v}
```
the return value can be expanded from an ArrayBuffer
to a synchronized ArrayBuffer.

While for:
```scala
val set = new HashSet[Int,String] with SynchronizedSet[Int,String] { }
val newbuf = set map {(k,v) => v}
```
the starting type is a synchronized Set but the return type
will be a simple buffer - no expansion is possible, so none
happens.


Using Builders and CanBuildFrom in Scala collections is both
clever and clean, but it has a problem.
Explicit pimping will fix the problem.
The "expandTo" and "optionalExpandTo" operations can be generated
at compile-time. When the compiler encounters a Traversable that
is extended with one or more traits, the compiler attempts to
generate the code needed to implement the "expandTo" and
"optionalExpandTo" operations. If this can not be done, if
the traits extending the Traversable are too complex, then
a compiler error is generated and the compilation fails.
Encountering such a failure, the programmer can either 1) fully flush
out the extended Traversable so that the Traversable methods that
use "newBuilder" and "CanBuildFrom" operate correctly or 2)
mark the Traversable extended with traits with a new, special,
annotation (for now, call it @BaseTraversableAllowed) that indicates 
that it is OK for the Traversable methods to return the base-Traversable
type rather than the full Traversable extended with traits type.

As an example of the use of the annotation:
```scala
@BaseTraversableAllowed
val a = new ArrayBuffer[T] with SynchronizedBuffer[T]
a filter {_ > 2} // OK returns ArrayBuffer
a map {v => v} // OK returns ArrayBuffer
```
Your input is appreciated, but I'm afraid we are no longer accepting "Suggestion" tickets on JIRA.

Available mechanisms for making suggestions include:
- the Scala mailing lists
- SIP (Scala Improvement Process) and SLIP (Scala Library Improvement Process)
- a pull request on GitHub implementing the suggestion
