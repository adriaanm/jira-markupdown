FWIW I am also seeing apparently the same problem in the following situation, and I have a work-around for the situation, which might help others or highlight a possible improvement to the scala compiler:

- Project depends on hadoop-client
- hadoop-common depends on commons-logging
- We exclude commons-logging dependency from hadoop-client and instead replace it with SLF4J's shim jcl-over-slf4j, a drop-in API replacement

We get:
```scala
[WARNING] Class org.apache.commons.logging.Log not found - continuing with a stub.
[ERROR] error while loading FileInputFormat, class file '/Users/srowen/.m2/repository/org/apache/hadoop/hadoop-core/1.0.4/hadoop-core-1.0.4.jar(org/apache/hadoop/mapred/FileInputFormat.class)' is broken
```

The class is available in jcl-over-slf4j, but is marked as "runtime" dependency since it is not used directly, and not needed -- by the likes of javac at least -- at compile time.

Changing the scope to "compile" makes it work, presumably because then scalac sees it, and it seems that without seeing it, this error occurs. I don't know if it's realistic, but ideally the behavior would match that of javac, which does not need knowledge of a dependency like this.
