First of all, there seems to be some confusion about the nature of Scala's Vector implementation. I don't know who spread the myth about the underlying data structure being a skip-list (I've read that in a couple of places now) but this is definitely false. The implementation is based on 32-wide trees, just as in Clojure. This renders any wholesale arguments (e.g. about locality) invalid.

While the trie structure is similar, there are some differences in how the implementation optimizes specific access patterns. Clojure chose a fairly simple model to make access to the right end faster: the last 32-wide block is kept outside the tree so that it can be accessed in constant time, without going through multiple tree levels. To add an element (on the right) to a Clojure Vector, only this max. 32-wide array has to be copied.

We took this model a step further. In Scala, Vectors have a notion of 'focus', which identifies a single 32-wide block that is accessible in constant time. Every update operation (be it at the left end, the right end, or any other position), will put the target block in focus. Updates to a block 'in focus' will copy only that particular 32-wide block (Clojure's implementation has to copy all blocks on the path to the root for positions that are not in the rightmost block). Moreover, all the tree nodes from the root to the block in focus are kept in a 'display', i.e. a constant-time stack. Moving the focus to an adjacent 32-block incurs only one indirection through the display (possibly copying the node one level up). Indexed reads also use the display to minimize the number of indirections.

The design decision behind this model is to optimize for spacio-temporal access locality. Sequentially rewriting parts of a Vector (starting from an arbitrary position) should be fast (Clojure's optimization for growing by appending to the right is a special case). Reading elements close to the last update should be fast. 

More generally, one central goal of the Vector design was to build the most versatile general purpose collection we could. This means that we tried to make as many operations as possible fast, but not optimize the hell out of a single one at the cost of others. As a corollary, we ruled out any model which is asymmetric regarding its left and right ends (we already have Lists) or only geared towards appending (we have Builders for that). Some operations we considered important are take, drop, takeRight, dropRight, splitAt etc (none of them are optimized in Clojure's or your implementation). Even more important is good support for Iterators and Builders because these are central to many other general collection operations. Your benchmarks show your implementation is 3 to 4 times slower for reverse, which is the only Iterator/Builder based operation you provide measurements for. My intuition is that others will show similar numbers. Without evidence that an implementation performs better on all Seq operations (well, let's say most) we cannot seriously consider it as a contender for replacing the current one.

What your implementation shows, however, is that indexed access can be done faster in some cases. This is not completely surprising (it's, well, a 2x speedup in a micro benchmark), so the question is whether the results can be generalized.

From my perspective, indexed access is an important operation, but for me it is not top priority. The cost of indexing is inherently log n so we can only get so far. A common use for indexing would be iteration, but iteration can in fact be done much faster. So I believe indexing is really only for random access. Now if a program's bottleneck is indeed random access performance, a log n collection will never do, and a speedup of 2 won't help. In that case, an ArrayBuffer or plain Array is the appropriate choice.

That said, it is worth to look at some details. In essence, your implementation seems to do two things differently: 

1) You use typed Array[Array[AnyRef]] instead of using Array[AnyRef] and then casting the AnyRef to Array[AnyRef] again. In my prototype this has been around 15% faster. Unfortunately, for implementing a fast concat operation (we hope to do that for 2.8.1 or 2.9) heterogenous Arrays seem to be necessary (we'll be storing Int arrays next to the sub nodes). We might rethink this however, and try to stick to homogeneous Arrays.

2) You use specialized subclasses for each possible tree height, instead of dispatching using if-then-else. In general, dispatch by subclassing favors monomorphic call sites. If-then-else is usually slower for monomorphic call sites, but gives better performance for megamorphic call sites. This is a classic best-case/worst-case tradeoff: for which case should one optimize? You picked the former, we picked the latter. I believe there are good arguments for both. Our reasoning, verified by experiments, was that since the collection API is implemented with a focus on reuse, there is a lot of indirection. In many cases HotSpot's inlining fails to duplicate the internal call sites to client code, and thus calls go to Seq or Iterable and from there to the real collection (which makes the call-site in Seq megamorphic). Also, Scalac's optimizer cannot inline any calls where the target is not statically known.

In your benchmarks, this doesn't show up since your call sites of apply are all monomorphic.

You also use very aggressive manual inlining. That's ok for implementing a small number of operations. But if you extend it to more operations, I could imagine it getting unwieldy. After all, somebody has to maintain the code. Another possible concern is that HotSpot is less likely to compile large methods (there might also be an instruction cache penalty).

In conclusion, we appreciate the effort you undertook in porting Clojure's Vector. Exploring different paths is always a valuable thing. As I have explained, we cannot accept it as a replacement in its current form. However, if you would like to help improve scala.collection.immutable.Vector, you are more than welcome. The current implementation is certainly not etched in stone. There are several avenues one could try: 1) Use typed Arrays, as you did, and see how that performs. 2) Instead of keeping a full 6-element display, keep only the bottom level (like Clojure, but with a variable focus position). 3) The current implementation has a large memory overhead for very small Vectors. Can we reduce that footprint? Obviously, we can build special subclasses for Vectors of 1,2,3,... elements, but that means we're again depending on monomorphic call sites. Another strategy would be turning the 6 display pointers into AnyRefs and making them hold actual data elements for Vectors of size <= 6. Again, this has to be carefully weighed against the cost of casting them to arrays for larger Vectors.

Cheers,
- Tiark
