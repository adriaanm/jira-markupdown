{code:scala}
    class Case2 {
      trait Container[+A] {
        def addAll[B >: A, T2 <: Container[B]](that: T2): Boolean
      }

      def t1: Container[Int] = ???
      def t2: Container[Any] = ???

      // Works
      t1.addAll[Any, Container[Any]](t2)

      // Errors:
      //* type mismatch; found : Case2.this.Container[Any] required: T2
      //* inferred type arguments [Int,Case2.this.Container[Any]] do not conform to method addAll's type parameter bounds [B >: Int,T2 <: Case2.this.Container[B]]
      t1.addAll(t2)
    }
{code}
Why can't least common supertype be inferred?
Type inference does not support bounds that refer to other type parameters. Why do you need T2? This works:
{code}
    def addAll[B >: A](that: Container[B]): Boolean
{code}

If you have to be able to specify the container, you could try:
{code}
    def addAll[B >: A, C[x] <: Container[x]](that: C[B]): Boolean
{code}

The inferred types then look like ` t1.addAll[Any, Container](t2)`
