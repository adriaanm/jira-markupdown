Martin, re-assigning to you as I can't figure out what's going wrong. Note that the anonymous class `A{}` and the absence of type argument to `B` are essential to reproduce.

First, I thought it was because case (3) of adapt creates a TypeApply tree like `[T <: A] B[T] [T]`
I [http://github.com/adriaanm/scala/commit/952245ef4a6385443564fccb5aaf25f012d05908#L2R796 changed] this to result in simply `B[T]', but that does not fix much.
(as an aside, that fix does prevent a very weird substitution. 
Before this change, the `TreeTypeSubstituter` in `inferMethodInstance` would substitute `T -> A`, which would change the tree `new [T <: A] B[T] [T]'  ->  `new [T <: A] B[T] [anonymous class $$anon]')

Then, I figure `typedTypeConstructor' might be at fault for using normalize instead of dealias, which would turn the type constructor `B` into `[T<:A]B[T]`, so I [http://github.com/adriaanm/scala/commit/952245ef4a6385443564fccb5aaf25f012d05908#L2R4161 changed that to use dealias]

the full patch I cobbled together so far is at:
http://github.com/adriaanm/scala/commit/952245ef4a6385443564fccb5aaf25f012d05908
