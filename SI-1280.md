Using 2.7.2.RC1. The problem is that if {{A}} is a type variable with a {{>: Null}} lower bound, then even if {{B >: Null}}, {{A with B}} won't be {{>: Null}}.

Super-contrived minimal example follows:

{code}
scala> trait X { x => type T >: Null; new X { type T = Any with x.T } }
<console>:5: error: error overriding type T in trait X with bounds >: Null <: Any;
 type T has incompatible type Any with X.this.T
       trait X { x => type T >: Null; new X { type T = Any with x.T } }
{code}

Replace {{Null}} above with any other type, and it works.

Maybe a bit simpler:

{code}
scala> trait T { type U >: Null
     | type V >: Null
     | }
defined trait T

scala> trait T1 extends T { type V = Any with U }
<console>:5: error: error overriding type V in trait T with bounds >: Null <: Any;
 type V has incompatible type Any with T1.this.U
       trait T1 extends T { type V = Any with U }
{code}
I'm sorry, but the answer doesn't satisfy me, and I can't avoid the impression that you have misunderstood the problem. The problem is _not_ that {{Null}} isn't getting some special treatment, but rather that a general typing rule doesn't apply to {{Null}} whereas it seems to apply to all other types (including {{Nothing}}). To reiterate:

If {{A >: L}} and {{B >: L}} then {{A with B >: L}}.

This rule should, as far as I can see, be safe for _all_ types, and with the current type system it already seems to be admissible for all the types I tested with... _except_ {{Null}}. Obviously, if {{A >: Null}} and {{B >: Null}}, then {{null}} also inhabits {{A with B}}, so your concern about empty types is already addressed by the general bounds checking mechanism. I don't see {{Null}} being any different from any other lower bound here.

As further proof that this is a compiler bug, consider that the problems in both my and Iulian's example can be worked around by simply parameterizing the lower bound so a literal {{Null}} doesn't appear in the code:

{code}
trait X[L] { x => type T >: L; new X[L] { type T = Any with x.T } }

trait T[L] { type U >: L; type V >: L }
trait T1[L] extends T[L] { type V = Any with U }
{code}

This doesn't yield any compiler errors with 2.7.2.RC1, and there are no problems instantiating {{L}} to {{Null}}.

So it very very much seems to me that in the compiler there is some special-cased handling for {{Null}} that rejects valid code.

I was unable to find anything in Aladdin about this.  If having subtyping behave correctly means that we lose type soundness, something is seriously wrong with the type system.  This with the fact that fixing SI-1208 would apparently break all sorts of things seems to indicate that we need to step back and really figure out what has gone wrong with the Scala type system before proceeding with additional features.
Tickets [http://scala-webapps.epfl.ch/bugtracking/bugs/displayItem.do?id=500 SI-500] and [http://scala-webapps.epfl.ch/bugtracking/bugs/displayItem.do?id=501 SI-501] seem like they might be the ones intended, but if they're directly related to this case, I'm probably a bit slow since I can't see it.

Anyway, _if_ {{L <: A, L <: B |- L <: A with B}} would, for some reason, be an unsound rule when {{L = Null}}, then the type system is _already_ broken due to the parameterized workaround.

And by my reading the above rule _is_ already contained in the spec, in 3.5.2:

> If {{T <: Ui}} for {{i = 1, . . . , n}} and [R is okay] then {{T}} conforms to the compound type {{{U1 with . . . with Un {R}}}.

I don't see any exceptions for {{T = Null}}.

You are right, SI-500 and SI-501 are not direct counter-examples. I remember now that we reasoned informally that type intersection would be similar but we never worked out a concrete example. I have done that now. Here it is:
{code}
class B
class C(x: String) extends B

class A {
  type A >: Null
  class D { type T >: C <: B }
  val x: D with A = null
  var y: x.T = new C("abc")
}
object Test extends A with Application {
  class C { type T = Int; val x = 1 }
  type A = C
  y = 42
}
{code}
(I'll add it to the test suite as null-unsoundness.scala).

If you compile the test with scalac, you get:
{code}
 found   : Null(null)
 required: A.this.D with A.this.A
  val x: D with A = null
                    ^
one error found
{code}
I then changed the condition which causes the error. It's in symtab/Types, method
isSubType0. One of the cases reads:

{code}
      case (_, RefinedType(parents2, ref2)) =>
        (parents2 forall (tp2 => tp1 <:< tp2)) &&
        (ref2.toList forall tp1.specializes) &&
        (tp1.typeSymbol != NullClass ||
        !parents2.exists(_.typeSymbol.isAbstractType))
{code}
I removed the last condition. Then the example compiles, but at runtime you see:
{code}
Exception in thread "main" java.lang.ExceptionInInitializerError
	at Test.main(nulls.scala)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to B
	at Test$$.<init>(nulls.scala:13)
	at Test$$.<clinit>(nulls.scala)
	... 1 more
{code}
So, here's the type hole. 

In summary, ``what's wrong with the Scala type system_ is that the idea of a universal value of null is fundamentally at odds with type abstraction. The cleanest fix would be to eliminate `null'. Failing that, we have to live with the restriction, or design a different scheme. But this should be a SIP; as you can see the issues are tricky and require a lot of study.
Thanks for taking the time to explain the issue in detail.

It seems to me that 500, 501 and this case are all various
symptoms of a common problem. The fixes have cured individual
symptoms (at the cost of rejecting some safe programs), but not
the underlying cause.

To my understanding, the underlying cause is the fact that a
stable identifier bound to {{null}} can have a singleton type.
With value members this "only" leads to a NullPointerException,
but with type members it leads to the situation that {{null}}
is accepted as a witness to prove that some type with given
constraints actually exists. And this is not always the case.

The fix to 501 and this case take different approaches, though:
the 501 fix (requiring bounds to be statically conforming) tries
to prevent us from even expressing "bad" constraints that
{{null}} would then illegally prove. In your above example,
however, we can _express_ the impossible constraints in {{{type T = Int } with { type T <: B }}}, but we just prevent
{{null}} from proving it.

I don't think {{null}} is inherently evil, but its interaction
with singleton types seems to be broken. To my understanding, it
would _in principle_ suffice to substitute {{NotNull}} in place of {{AnyRef}} in section 3.2.1 of the spec, though this would of
course bring enormous practical difficulties. But it seems like
the right thing to do. Then the all the fixes to individual
symptoms could be removed.

It's funny, now I realize that my ticket SI-1273 is completely
upside down: it's _right_ that {{Null <: Singleton}} doesn't
hold. The problem is instead that {{Null <: p.type}} holds. :)

Have I understood the situation correctly?

As I said previously, if the type system can be broken without the current restrictions on {{Null}}, it can be broken even with them, thanks to the parameterization workaround. This turns out to be true, since the following breaks even unmodified RC1. So, once again, _Scala is unsound_.

{code}
  class C[L, A >: L, B >: L](l : L) { 
    val x : A with B = l
  }

  class D[B >: Null] extends C[Null, { type X >: String}, B](null) { 
    var y : x.X = "foo" 
  }

  val v : Int = new D[{type X <: Int}].y
{code}

This yields:

{code}
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(Unknown Source)
	at .<init>(<console>:6)
{code}

Abstract type members can also be used instead of type parameters.

I guess it's possible to add some more ad-hoc checks that prevent more of these kinds of problems, but they still can't guarantee that more of the same kind won't turn up. Forbidding {{null}} from having a singleton type seems like the only real solution.
