=== What steps will reproduce the problem (please be specific and use wikiformatting)? ===

The following code works in 2.8.1:
{code}
import org.apache.hadoop.io.{NullWritable, LongWritable, Text}
import org.apache.hadoop.mapreduce.{Mapper, Job}


object MyJob {
  def main(args:Array[String]) {
    val job = new Job(new Configuration())
    job.setMapperClass(classOf[MyMapper])
    
  }
}

class MyMapper extends Mapper[LongWritable,Text,Text,Text] {
  override def map(key: LongWritable, value: Text, context: Mapper[LongWritable,Text,Text,Text]#Context) {

  }
}

{code} 

=== What do you see instead? ===
I get this compiler error:

{code}
error: type mismatch;
found   : java.lang.Class[MyMapper](classOf[MyMapper])
required: java.lang.Class[_ <: org.apache.hadoop.mapreduce.Mapper]
job.setMapperClass(classOf[MyMapper])
{code}


=== Additional information ===
Daniel Sobral vry helpfully directed me here from my Stack Overflow question at (http://stackoverflow.com/questions/6028221/how-does-one-implement-a-hadoop-mapper-in-scala-2-9-0).

The method definition of the failing call (Job.setMapperClass) is this:

{code}
public void setMapperClass(java.lang.Class<? extends org.apache.hadoop.mapreduce.Mapper> cls) throws java.lang.IllegalStateException { /* compiled code */ }
{code}

The method definition of Mapper itself is this:

public class Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT>


=== What versions of the following are you using? ===
  - Scala: 2.8.1 and 2.9.0
  - Java: latest
  - Operating system: OSX / Linux
(comment by extempore):

This is induced by the use of a type constructor as a bound. Much simplified:

{code}

// J.java
public class J<T> {
  public static void f(java.lang.Class<? extends J> cls) { }
  // correctly it should be like this, and then it would work.
  // unfortunately that doesn't mean we don't have to deal with it.
  // public static void f(java.lang.Class<? extends J<?>> cls) { }
}
// S.scala
class S extends J[AnyRef]

object Test {    
  def main(args:Array[String]) {
    J.f(classOf[S])
  }
}
{code}


This results in:

{code}

S.scala:5: error: type mismatch;
 found   : java.lang.Class[S](classOf[S])
 required: java.lang.Class[_ <: J]
    J.f(classOf[S])
               ^
one error found
{code}


I don't immediately see how to work around it from the scala side alone, because scala is picky about how we express these things.

{code}

// nope
J.f(classOf[S]: Class[_ <: J[_]])

S.scala:5: error: type mismatch;
 found   : Class[_$1(in method main)] where type _$1(in method main) <: J[_]
 required: java.lang.Class[_ <: J]
    J.f(classOf[S]: Class[_ <: J[_]])
                  ^
one error found

// nope
J.f(classOf[S]: Class[J[_]])

S.scala:5: error: type mismatch;
 found   : java.lang.Class[S](classOf[S])
 required: Class[J[_]]
Note: S <: J[_] (and java.lang.Class[S](classOf[S]) <: java.lang.Class[S]), but Java-defined class Class is invariant in type T.
You may wish to investigate a wildcard type such as `_ <: J[_]`. (SLS 3.2.10)
    J.f(classOf[S]: Class[J[_]])
               ^
one error found

// naturally, nope
J.f(classOf[S]: Class[J])

S.scala:5: error: class J takes type parameters
    J.f(classOf[S]: Class[J])
                          ^
one error found
{code}
It is indeed yourself, in r24275.

commit d832118727bc6ffc1b87519086bae47e06090bb6
Author: odersky <odersky@5e8d7ff9-d8ef-0310-90f0-a4852d11357a>
Date:   Sun Feb 13 15:04:53 2011 +0000

    More tweaks to rawToExistential to avoid pile-up of transformations.
    
    git-svn-id: http://lampsvn.epfl.ch/svn-repos/scala/scala/trunk@24275 5e8d7ff9-d8ef-0310-90f0-a4852d11357a

I was unable to duplicate Ismael Juma's finding that this is fixed in 2.9.0-1.  I created an sbt project with build.properties like:

{code}
project.scratch=true
project.name=test
sbt.version=0.7.7
project.version=1.0
build.scala.versions=2.9.0-1
project.initialize=false
{code}

The build/Project.scala looked like:

{code}
import sbt._

class Project(info: ProjectInfo) extends DefaultProject(info) {
  val clouderaRepo = "cloudera release" at "https://repository.cloudera.com/content/repositories/releases"
  val cdhVer = "0.20.2-cdh3u0"
  val hadoopCore = "org.apache.hadoop" % "hadoop-core" % cdhVer % "provided"
}
{code}

The project contained exactly one source file:

{code}
import org.apache.hadoop._
import org.apache.hadoop.io._
import org.apache.hadoop.conf._
import org.apache.hadoop.mapreduce._

object MyJob {
  def main(args:Array[String]) {
    val job = new Job(new Configuration())
    job.setMapperClass(classOf[MyMapper])
  }
}

class MyMapper extends Mapper[LongWritable,Text,Text,Text] {
  override def map(key: LongWritable, value: Text, context: Mapper[LongWritable,Text,Text,Text]#Context) {
  }
}
{code}

Compiling resulted in the following error message
{code}
[error] ....MyJob.scala:9: type mismatch;
[error]  found   : java.lang.Class[MyMapper](classOf[MyMapper])
[error]  required: java.lang.Class[_ <: org.apache.hadoop.mapreduce.Mapper]
[error]     job.setMapperClass(classOf[MyMapper])
[error]                               ^
[error] one error found
{code}
For an unknown reason, the workaround of defining the mapper and reducer before the job stopped working when I added enough files to my project.  I didn't notice the problem until I made a change that caused sbt (v0.10) to have to recompile a few files.  Now I see an error like:
{code}
[error]  found   : java.lang.Class[MyReducer](classOf[MyReducer])
[error]  required: java.lang.Class[_ <: org.apache.hadoop.mapreduce.Reducer]
[error]     job.setCombinerClass(classOf[MyReducer])
{code}
See also duplicate SI-4769.  I can see exactly what line is causing this and removing the line does fix this.  Unfortunately there is no test case to give me an idea of what the line is supposed to be preventing.
Here's what I ran into, which might make a nicer test case than Hadoop because all the required classes come with the JDK:

{code}
package something.weird

import javax.xml.bind.annotation.adapters.{XmlAdapter,XmlJavaTypeAdapter}
import scala.reflect.BeanInfo

@BeanInfo class Intermediate {
    var foo : String = _
    var bar: String = _
}

@XmlJavaTypeAdapter(classOf[Adapter]) class Original(val foo: String, val bar: String) { 
}

class Adapter extends XmlAdapter[Intermediate, Original] { 
    def marshal(o: Original) : Intermediate = null
    def unmarshal(i: Intermediate) : Original = null
}
{code}

Compiles in 2.8.1, fails in 2.9.0 with 

{code}
[error] jaxb.scala:11: type mismatch;
[error]  found   : java.lang.Class[something.weird.Adapter](classOf[something.weird.Adapter])
[error]  required: java.lang.Class[_ <: javax.xml.bind.annotation.adapters.XmlAdapter]
[error] @XmlJavaTypeAdapter(classOf[Adapter]) class Original(val foo: String, val bar: String) {
{code}
See also duplicate SI-4822.
We ran into a problem similar to [~themel] (a colleague of mine opened SI-4822). I think it's safe to assume that the raw types issue exists across the JDK and 3rd party libraries and since we can't get anyone else to fix it, I recon a fix in the Scala compiler is needed - even though this is not strictly a bug in the compiler...
(odersky in [r25394|https://codereview.scala-lang.org/fisheye/changelog/scala-svn?cs=25394]) Closes #4603. Review by extempore.
(extempore in [r25403|https://codereview.scala-lang.org/fisheye/changelog/scala-svn?cs=25403]) Test case for SI-4603, no review.
Verified that the problem is fixed in 2.9.1.RC3 for our code.  Many thanks!  And the compiler is snappier too!


Hello,
I'm facing a similar issue in Scala 2.10.3, +only+ when extending a Java class from a Scala class. This issue is not reproduced if AMapper (see code below) is implemented as a Scala class.

h4. Code

Here is my project layout:

{code}
src
  main
    java
      myhadoop
        AMapper.java
    scala
      myhadoop
        MyMapper.scala

{code}

And these are my classes' sources:

{code:title=AMapper.java source code}
package myhadoop;

import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class AMapper extends Mapper<Text, BytesWritable, Text, Text> {
  public void handleThis(Text key, Mapper<Text, BytesWritable, Text, Text>.Context context, Text text) {
    // not relevant to this test
  }
}
{code}

{code:title=MyMapper.scala source code}
package myhadoop

import org.apache.hadoop.io.{BytesWritable, Text}
import org.apache.hadoop.mapreduce.Mapper

class MyMapper extends AMapper {
 
  override def map(key: Text, value: BytesWritable, context: Mapper[Text, BytesWritable, Text, Text]#Context) {
    handleThis(key, context, new Text(value.getBytes))
  }
}
{code}

h4. Error

Compiling this code will raise the following error:

{code}
error: type mismatch;
found: org.apache.hadoop.mapreduce.Mapper[org.apache.hadoop.io.Text,org.apache.hadoop.io.BytesWritable,org.apache.hadoop.io.Text,org.apache.hadoop.io.Text]#Context
required: org.apache.hadoop.mapreduce.Mapper[KEYIN,VALUEIN,KEYOUT,VALUEOUT]#Context
{code}

pointing to the {{handleThis(key, context, new Text(bytes))}} line.

h4. Environment

Scala 2.10.3
Java 1.7.0u21
Ubuntu Linux 12.04
