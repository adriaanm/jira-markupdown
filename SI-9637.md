scala> Seq(1.0, Double.NaN, 2.5E-4).max
res2: Double = 2.5E-4

From a user point of view it would be great if this operation could
return NaN.
I consider this a bug indeed, as for any collection `seq`, `seq.max` should be always equal to `seq.reduce(max)`. Unfortunately, this happens because the ordering for `Float` and `Double` values follow the IEEE convention where floating-point values are never smaller, larger or equal to NaN. Therefore, implementing ordering-based operations on sequences with comparison operators would always lead to inconsistencies.

Implementing `max` via `reduce(ordering.max)` would solve the problem, as the `Ordering` instances of floating-point values already consider this special case. However, the current signature (`min[B >: A](implicit cmp: Ordering[B]): A`) doesn't allow this, as `cmp.max` returns a `B`, not an `A` as required. We can't rely on checking which argument the result is equal to, as NaN is not equal to NaN.

The only way I see to fix this without changing the method signature is explicitly checking if we are dealing with `Float` or `Double` and find the min/max value accordingly. It's very hacky and won't work on user-defined types with the same semantics, but I can't think of other way right now. @Ichoran, what do you think?     
@ruippeixotog - I think under the circumstances special-casing `max` to check whether it's got an instance of Ordering.Double or Ordering.Float is a reasonable solution.

You could also explicitly check the semantics of NaN values: a NaN is *not even equal to itself*, which lets you detect it.  But I'm not sure it's worth the extra runtime.
