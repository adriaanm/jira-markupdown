scala> var s:String = null;
s: String = null
scala> s.+(s)
res3: java.lang.String = nullnull
scala> s.length
java.lang.NullPointerException

According to the language Spec, �12.3.1, + is a binary operator, and in Scala operators are just methods with an argument, i.e. 
    s+s is sugar for s.+(s) 

If s above is the Null Pointer, s.+(s) should throw an NPE,
whereas if it is a String, s.length should *not* throw NPE.

The issue has been discussed in the scala list under the heading 
"null + null = ??" and the conclusion seems to be that it can't be talked away, but it is a bug in the Spec

What versions of the following are you using?
Scala: 2.8
Java: 1.6
Operating system: Windows 7
Replying to [comment:1 ittayd]:
> To complete the description, from the discussion, it looks like this is a bug, since 's + s' is actually converted to 'any2stringadd(s).+(s)' where any2stringadd does 'new StringAdd(s)'. So StringAdd (or StringAdd#+) can throw and NPE and the behavior would be consistent with the spec.

This muddies the issue, is inaccurate, and seems to value error for error's sake.

First of all, that's not at all how 's + s' compiles, assuming s is a String, which is the point of the discussion.  It compiles to
{code}
  new StringBuilder append s append s toString
{code}

There are two separate things.

{code}
1) String is given a '+' method by the compiler.
2) There is an implicit conversion from Any which gives the impression everything has a '+' method.
{code}
Only 1) is relevant to this bug.  2) is only relevant inasmuch as it instructs of the very low significance of the bug, because it implies that with or without the '+' method, there is no NPE.

The bug, if indeed there is one, is only that the spec wording is ambiguous about what "taken to support a method" means and whether one should expect semantics indistinguishable from it actually possessing the method.  It is an "angels on the head of a pin" issue.  There are 571 other open tickets, in case it makes any difference to anyone.

Recommendation: change the wording in SLS 12.3.1 to "concatenates the textual representation of its left operand with the textual representation of its right operand."
The SLS in Section 6.3 lists six methods, which the null value is supposed to understand:
     eq, ==, ne, !=, isInstanceOf, and asInstanceOf
and then it continues :
  "A reference to any other member of the “null” object causes a NullPointerException to be thrown."

Apparently, this is not the case with the current compiler.

Changing the wording in SLS 12.3.1 only camouflages the problem.

> Apparently, this is not the case with the current compiler. 

You are not referencing the '+' member of the Null when you write (null: String) + "a".  You are referencing the '+' member of String.  null is a String, you know.  See:
{code}
scala> var x: String = null
x: String = null
{code}
Try to reference the '+' member of Null:
{code}
scala> null + "abc"        
<console>:6: error: value + is not a member of Null
       null + "abc"
            ^  
{code}
Look, it's too smart to let you hurt yourself like that.  (This does represent a spec deviation, not to mention more fundamental issues with substitutability, but Null is always a whirlwind of contradiction.)

> Changing the wording in SLS 12.3.1 only camouflages the problem. 

I'm sorry but I question your understanding of the problem.  You seem to be very invested in this issue, and I encourage you to take a while paging through the open bugs in trac to maybe gain some perspective about what's important.

There ARE a bunch of issues with null, but by focusing on String.+ you're only finding them by periodically bumping into them in the periphery.

> You are not referencing the '+' member of the Null when you 
> write (null: String) + "a". You are referencing the '+' 
> member of String. null is a String, you know.

If (null:String) is a String, then why does (null:String).length throw a NPE ?  

> I'm sorry but I question your understanding of the problem. 

Help me to become as smart as yourself by pointing me to a place where Scala's null values are specified or explained.

> You seem to be very invested in this issue. 
If you mean to resolve the problem by personal insinuation, I'll leave you alone.

Looking at this again (because I'm neurotic), it seems that the behavior of the `+` operation is _not_ "the same regardless of whether the left operand is typed as String", because StringAdd's `+` method takes a `String` argument rather than an `Any`. If you change the spec as I suggested in my previous comment, this will have to be changed as well.
Replying to [comment:10 anovstrup]:
> Looking at this again (because I'm neurotic), it seems that the behavior of the `+` operation is _not_ "the same regardless of whether the left operand is typed as String", because StringAdd's `+` method takes a `String` argument rather than an `Any`. If you change the spec as I suggested in my previous comment, this will have to be changed as well.

That String argument is the right operand of `+`; the left operand is self:Any.

I agree with your suggested change to the SLS, which shows how Paul's issue 2 *is* relevant to this bug.

I find HPGumm's "Changing the wording in SLS 12.3.1 only camouflages the problem" rather odd, since his original complaint was about behavior being determined by what the compiler does rather than by a formal specification ... how can a change in the specification "only camouflage" a problem when the specification is the only authority? Does he now want the compiler to produce an NPE even if the spec says it doesn't?

"Implicit conversions in general carry the danger of appearing to give behavior to null values, contrary to the spec."

That is *not* contrary to the spec; the spec refers to "A reference to any other member of the “null” object" but implicitly applied methods *aren't* members of the “null” object. It would not only be unwise, but impossible, to enforce implicit conversions throwing NPE's when applied to null because in general they are arbitrary user code and can do whatever they please.

Replying to [comment:11 jibal]:
> "Implicit conversions in general carry the danger of appearing to give behavior to null values, contrary to the spec."
> 
> That is *not* contrary to the spec; the spec refers to "A reference to any other member of the “null” object" but implicitly applied methods *aren't* members of the “null” object. It would not only be unwise, but impossible, to enforce implicit conversions throwing NPE's when applied to null because in general they are arbitrary user code and can do whatever they please.

Agreed, but I think my comment was unclear.  Implicit conversions do not give behavior to null values contrary to the spec, but they can _appear_ to give behavior to null values contrary to the spec. My point was that any library developer (especially the developers of the standard library) must weigh the benefits of any implicit conversion against the potential confusion they can cause.
Replying to [comment:11 jibal]:
> Replying to [comment:10 anovstrup]:
> > Looking at this again (because I'm neurotic), it seems that the behavior of the `+` operation is _not_ "the same regardless of whether the left operand is typed as String", because StringAdd's `+` method takes a `String` argument rather than an `Any`. If you change the spec as I suggested in my previous comment, this will have to be changed as well.
> 
> That String argument is the right operand of `+`; the left operand is self:Any.

Ah, just noticed another point of confusion.  My point was that {{ (null: List[Int]) + 1 }} does not behave the same as {{ (null: String) + 1 }}, precisely because StringAdd's `+` method can only accept a `String` as the right operand.
Replying to [comment:13 odersky]:
> The behavior of `(null: String) + "abc"` is certainly intended. I'll update the spec to talk about which implicit conversions are available in Predef.

That would certainly be a good idea; there is no Scaladoc documentation for, e.g., ensuring -- it seems to be described only in external commentary such as your book.

But what about "abc" + (null: Any), or "abc" + ("def": Any)? That is handled internally by the compiler, *as if* there were an implicit conversion in Predef, but there isn't one AFAICS. (anovstrup, this applies to your point (of confusion)).

Replying to [comment:12 anovstrup]:
> Replying to [comment:11 jibal]:
> > "Implicit conversions in general carry the danger of appearing to give behavior to null values, contrary to the spec."
> > 
> > That is *not* contrary to the spec; the spec refers to "A reference to any other member of the “null” object" but implicitly applied methods *aren't* members of the “null” object. It would not only be unwise, but impossible, to enforce implicit conversions throwing NPE's when applied to null because in general they are arbitrary user code and can do whatever they please.
> 
> Agreed, but I think my comment was unclear.  Implicit conversions do not give behavior to null values contrary to the spec, but they can _appear_ to give behavior to null values contrary to the spec. My point was that any library developer (especially the developers of the standard library) must weigh the benefits of any implicit conversion against the potential confusion they can cause.

Well, this is a bug report about the spec, not guidance about library design. But on that score:

The design of Scala is committed to the use of implicits, which are non-local effects that can give all sorts of contrary-to-spec _appearances_, as code readers go hunting around in the receiver class and superclasses looking for where those methods are defined and failing to find them. In the REPL, if I type "1".<TAB> I do not see toInt as a possible method, yet "1".toInt is valid Scala. I think this is a very serious problem with the usability of the language that goes way beyond this minor stuff about absent NPE's. But it's not so much a reason for library developers to not use implicits as it is a reason to develop documentation tools that do not ignore the impact of implicits. The REPL, and every IDE, should invoke the compiler to tell me exactly what methods I can apply at that point, and Scaladoc should gather up every implicit def into a special listing that tells me what implicit methods apply if I import the enclosing scope -- I should not have to peruse the source to find the types of the left operands and then go look at the source of the return type to find the type of the right operand and the name of the method -- that's madness.
