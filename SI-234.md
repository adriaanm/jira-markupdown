{code}
sealed abstract class DeferredResult[+A] {
   def ! : A
}
case class Return[+A](x:A) extends DeferredResult[A] {
   def ! = x
}
object Defer {
   def apply[A](n: => DeferredResult[A]) = new Defer(n)
   def unapply[A](x:Defer[A]) = Some(x next)
}
class Defer[+A](n: => DeferredResult[A]) extends DeferredResult[A] {
   def ! = evaluate(this)
   def next = n

   private final def evaluate[B](x: DeferredResult[B]):B = x match {
      case Return(result) => result
      // a cast is added after evaluate
      case chain:Defer[_] => evaluate(chain.asInstanceOf[Defer[B]] next)
   }
}
{code}

Here are the trees after type checking (only the relevant part):

{code}
    final private def evaluate[B >: Nothing <: Any](x: DeferredResult[B]): B = x match {
      case (B)Return[B]((result @ _)) => result
      case (chain @ (_: Defer[_])) => Defer.this.evaluate[B](chain.asInstanceOf[Defer[B]].next).asInstanceOf[B]
    }
{code}

The last call to {{asInstaceOf[B]}} seems useless, and prevents the tail call phase to rewrite the call to a jump.
