I'm trying to use a modified version of https://github.com/romix/akka-kryo-serialization with Scala 2.10.0-RC5. It compiles fine (without -optimise, with the flag it crashes, but that's a different issue), but then at class load-time I get the following error:

```
Could not run test org.hyflow.KryoTest: java.lang.VerifyError: (class: com/romix/scala/serialization/kryo/ScalaSetSerializer, method: create signature: (Lcom/esotericsoftware/kryo/Kryo;Lcom/esotericsoftware/kryo/io/Input;Ljava/lang/Class; )Lscala/collection/Set; ) Inconsistent stack height 1 != 3
```

Even Soot refuses to load the class properly, and gives the following:

```
Considering 111: invokenonvirtual[111]
Exception in thread "main" java.lang.RuntimeException: TypeStack merging failed; unequal stack lengths: 1 and 3
	at soot.coffi.TypeStack.merge(TypeStack.java:137)
	at soot.coffi.CFG.jimplify(CFG.java:1196)
	at soot.coffi.CFG.jimplify(CFG.java:955)
	...
```

The code that causes the problem appears to be at the end of this block, as the three branches are collected into the final result (line labeled 111 in the 2.10 bytecode file):

```scala
var coll: Map[Any, Any] = 
if(classOf[SortedMap[_,_]].isAssignableFrom(typ)) {
// Read ordering and set it for this collection 
implicit val mapOrdering = kryo.readClassAndObject(input).asInstanceOf[scala.math.Ordering[Any]]
	try typ.getDeclaredConstructor(classOf[scala.math.Ordering[_]]).newInstance(mapOrdering).asInstanceOf[Map[Any,Any]].empty 
	catch { case _ => kryo.newInstance(typ).asInstanceOf[Map[Any,Any]].empty }
} else {
	kryo.newInstance(typ).asInstanceOf[Map[Any,Any]].empty
}
```

This code worked on 2.9.1, and it appears the generated bytecode is indeed different. I've attached the source code excerpt and disassembled bytecode for 2.9.1 and 2.10.0-RC5, and highlighted the line with the problem in the 2.10 bytecode.
The minimal test case that generates the error seems to be:

```scala
def test(kryo: Kryo, input:Input, typ: Class[Map[_,_]]): Map[_,_] = {
	val len = 7
	var coll: Map[Any, Any] = {
		try { 
			val someVar = null;
			Map[Any,Any]().empty 
		} catch { 
			case _ => Map[Any,Any]().empty 
		}
	}
	0 until len foreach {_ => coll += Tuple2( 0, 0) }
	coll
}
```

Looks similar to #5380 , and seems to be related to the wrapping of "coll" into a scala.runtime.ObjectRef . someVar is required but probably just prevents some other optimization.
How about this?

```scala
object Main extends App {
	def test(): Map[_,_] = {
		//val typ = classOf[Map[Int,Int]]
		var coll: Map[Int, Int] = {
			val key = 4
			try {
				Map[Int,Int](key -> 5).empty 
			} catch { case _ => Map[Int,Int](2 -> 3).empty }
		}
		0 until 7 foreach {_ => coll += Tuple2( 0, 0) }
		coll
	}
}
```

It fails for me using 2.10.0-RC5 and:
```scala
#!/bin/bash
rm ./*.class
scalac  bug.scala
scala -classpath . Main
```
Further minimization:

```
object Test {

  def main(args: Array[String]) {

    var coll = {
      val key = 4
      try   { null }
      catch { case _ => null }
    }

    { () => coll } // the purpose of this is making `coll` an ObjectRef

  }
}
```

After compiling with v2.10.0 and master we get: 

```
java.lang.VerifyError: (class: Test$, method: main signature: ([Ljava/lang/String;)V) Inconsistent stack height 1 != 3
```
As a sidenote, removing `val key = 4` also removes the `VerifyError`: the emitted bytecode contains two code sections, one for the try-clause and another for the catch-clause (both doing the same, ie building an `ObjectRef` with `null` as payload). In this case, there's no `VerifyError` because on control-flow merge those stacks have same height.
Back to the example in [#comment-61651]. Here's the javap:

```
public void main(java.lang.String[]);
  Code:
   0:   new     #16; //class scala/runtime/ObjectRef
   3:   dup
   4:   iconst_4
   5:   istore_3
   6:   aconst_null
   7:   goto    12
   10:  pop
   11:  aconst_null
   12:  pop
   13:  aconst_null
   14:  invokespecial   #19; //Method scala/runtime/ObjectRef."<init>":(Ljava/lang/Object;)V
   17:  astore_2
   18:  new     #21; //class Test$$anonfun$main$1
   21:  dup
   22:  aload_2
   23:  invokespecial   #24; //Method Test$$anonfun$main$1."<init>":(Lscala/runtime/ObjectRef;)V
   26:  pop
   27:  return
  Exception table:
   from   to  target type
     6    10    10   any
```

Two blocks (B1 and B2) get merged at instruction 12. B1 comprises instructions [0 to 7] and B2 (an exception handler) [10 to 11].

On exit from B1, the stack is `[ObjectRef ObjectRef null]`
On exit from B2, the stack is `[null]`
Therefore the VerifyError `Inconsistent stack height 1 != 3`

Usually `liftTree()` in `UnCurry` avoids the situation above, by creating a local method for the try expression:

```
 *  - convert try-catch expressions in contexts where there might be values on the stack to
 *      a local method and a call to it (since an exception empties the evaluation stack):
 *
 *      meth(x_1,..., try { x_i } catch { ..}, .. x_b0) ==>
 *        {
 *          def liftedTry$1 = try { x_i } catch { .. }
 *          meth(x_1, .., liftedTry$1(), .. )
 *        }
```

That would have saved the day.
Here's the story. 

Remove some redundant code
https://github.com/scala/scala/commit/b2f3fb271342d7862cc045f5ee5cff6815ac9722

Remove the code that it was redundant to, so now it
can't work
https://github.com/scala/scala/commit/beb875187914b12b1b9dbb5621447067e2926c7c

Then destroy the evidence that it ever existed
https://github.com/scala/scala/commit/ffc2389840852a120fecd772206d55db9a79f30e

Moral of the story: tests are good.
There is a (way) simpler solution. The bug results from UnCurry not anticipating that the location of a try-catch will become non-statement after LambdaLift. That's because LambdaLift turns a statement-position try-catch into non-statement-position (by giving the enclosing RHS as argument to `new OBjectRef(initialValue)`. The only way to lower such `New()` is:

```scala
NEW ObjectRef
DUP
... instructions loading initialValue
INVOKESPECIAL scala.runtime.ObjectRef.<init>(initialValue)
```

Alternatively, if the above were lowered into:

```scala
... instructions loading initialValue
INVOKESTATIC scala.runtime.ObjectRef.create(initialValue)
```

then UnCurry wouldn't need to anticipate anything (no code resurrection, no code duplication, more compact code). For bonus points, it would be great to have:

```scala
INVOKESTATIC scala.runtime.ObjectRef.zero()
```

which returns an `ObjectRef` initialized to `null`. Similarly for the zeroes of `IntRef` and others.

About binary compatibility, what if `ObjectRef` et al. had been designed from the start with the above in mind? It's never too late.

An alternative that doesn't break binary compatibility is

```scala
var x = try{...}catch{...}
```

transforms to

```scala
val temp$ = try {...}catch{...}
var x = temp$
```

which, when x is captured, turns turns into 
```scala
... instructions loading initialValue
STORE temp$
NEW ObjectRef
DUP
LOAD temp$
INVOKESPECIAL scala.runtime.ObjectRef.<init>(initialValue)
```

It wastes a variable slot in cases when var is not captured, though (unless we're smarter about optimizing away variables than I think we are), so we'd want to replace it with the cleaner static factory version in 2.11.
The extra-variable is actually lightweight, and apparently LambdaLift isn't too late to apply it (I'm guessing here). Perhaps detecting new Foo(try{...}catch{...}) during LambdaLift is also amenable to a local rewriting 

```scala
var temp = try {} catch {}
new Foo(temp)
```

I agree getting this fixed first in a binary-compatible way is the best for now.
It turns out to be even simpler than all this discussion. So simple I feel quite stupid for not seeing it the first time through. The original problem was that var x = try {...} catch {...} works fine but that var x = { blah; try{...} catch{...} does not. Well, in lambda lift there's a transformation that turns var x = try {block} catch {case blah => catchBlock} into var x = try {new Ref(block)} catch {case blah => new Ref(catchBlock)}. But that didn't catch the case where x was initialized from a block. The fix is easy. Just look at a block used for captured var assignment and do the same rewrite on the block's result expression. Do it recursively since we could have var x = {blah {blurg { try...}}.
One of the sub-problems when try-catch's are left in expression positions is a post-CleanUp step to guarantee empty-stack-on-try-entry. Other backends (in particular MSIL) also stand to benefit.

A proposal (in the form of pseudocode) for that transformation can be found at https://groups.google.com/d/msg/scala-internals/VkEL7wOVQpE/aSiNnF3ym-cJ

